#!/usr/bin/env python3
import json
import re
import ssl
import urllib.parse
import urllib.request
import xml.etree.ElementTree as ET
from datetime import datetime
from zoneinfo import ZoneInfo
from pathlib import Path

TZ = ZoneInfo("Asia/Singapore")
OUT = Path("/Users/lin/.openclaw/workspace/web_pages/hotnews/data/news.json")

SOURCES = {
    "ä¸­å›½": ["http://www.people.com.cn/rss/politics.xml"],
    "ç¾Žå›½ï¼ˆæ¬§ç¾Žåª’ä½“ï¼‰": [
        "http://rss.cnn.com/rss/edition.rss",
        "https://feeds.bbci.co.uk/news/world/rss.xml"
    ],
    "ä¼Šæ–¯å…°ï¼ˆåŠå²›ç­‰ï¼‰": ["https://www.aljazeera.com/xml/rss/all.xml"],
}

MAX_ITEMS = 30
MAX_CARD_ITEMS = 16
MAX_TRIANGLE = 10
STOPWORDS = {
    "the","a","an","to","of","for","in","on","at","and","or","with","from","is","are",
    "china","chinese","us","u.s","america","american","al","jazeera","says","new","after","over",
    "global","world","news","update","live"
}


def clean_text(s: str) -> str:
    return re.sub(r"\s+", " ", (s or "")).strip()


def translate_text(text: str, target: str = "zh-CN"):
    if not text:
        return ""
    try:
        q = urllib.parse.quote(text)
        u = f"https://translate.googleapis.com/translate_a/single?client=gtx&sl=auto&tl={target}&dt=t&q={q}"
        req = urllib.request.Request(u, headers={"User-Agent": "Mozilla/5.0"})
        with urllib.request.urlopen(req, timeout=12) as r:
            data = json.loads(r.read().decode("utf-8", errors="ignore"))
        return "".join(part[0] for part in data[0] if part and part[0]).strip() or text
    except Exception:
        return text


def enrich_bilingual(item: dict):
    title = item.get("title", "")
    item["title_en"] = translate_text(title, "en")
    item["title_zh"] = translate_text(title, "zh-CN")
    return item


def fetch_rss(url: str):
    ctx = ssl.create_default_context()
    req = urllib.request.Request(url, headers={"User-Agent": "Mozilla/5.0 OpenClawNewsBot"})
    with urllib.request.urlopen(req, timeout=20, context=ctx) as r:
        data = r.read()

    root = ET.fromstring(data)
    items = []

    for item in root.findall(".//channel/item"):
        title = clean_text(item.findtext("title"))
        link = clean_text(item.findtext("link"))
        pub = clean_text(item.findtext("pubDate"))
        if title and link:
            items.append({"title": title, "link": link, "published": pub})

    if not items:
        ns = {"a": "http://www.w3.org/2005/Atom"}
        for entry in root.findall(".//a:entry", ns):
            title = clean_text(entry.findtext("a:title", default="", namespaces=ns))
            link_el = entry.find("a:link", ns)
            link = clean_text(link_el.attrib.get("href", "") if link_el is not None else "")
            pub = clean_text(entry.findtext("a:updated", default="", namespaces=ns))
            if title and link:
                items.append({"title": title, "link": link, "published": pub})

    seen, dedup = set(), []
    for it in items:
        key = (it.get("title", ""), it.get("link", ""))
        if key in seen:
            continue
        seen.add(key)
        dedup.append(enrich_bilingual(it))

    return dedup[:MAX_ITEMS]


def tokenize(title: str):
    words = re.findall(r"[A-Za-z]{3,}", title.lower())
    return {w for w in words if w not in STOPWORDS}


def match_score(a: str, b: str):
    ta, tb = tokenize(a), tokenize(b)
    if not ta or not tb:
        return 0
    return len(ta & tb)


def best_for(base, arr):
    best, bs = None, 0
    for x in arr:
        s = match_score(base["title"], x["title"])
        if s > bs:
            best, bs = x, s
    return best, bs


def ai_view(event):
    zh = (event.get("ä¸­å›½", {}) or {}).get("title_zh", "")
    us = (event.get("ç¾Žå›½", {}) or {}).get("title_zh", "")
    aj = (event.get("ä¼Šæ–¯å…°", {}) or {}).get("title_zh", "")
    combined = f"{zh} {us} {aj}"

    # è´¢ç»ç»æµŽç±»
    if any(k in combined for k in ["å…³ç¨Ž", "è´¸æ˜“", "ç»æµŽ", "é€šèƒ€", "å¸‚åœº", "è‚¡å¸‚", "è´¢æ”¿", "åˆ©çŽ‡", "é“¶è¡Œ", "æŠ•èµ„", "è´§å¸", "æ±‡çŽ‡"]):
        return (
            "ðŸ“Š æˆ‘çš„æ·±åº¦åˆ†æžï¼ˆè´¢ç»ç±»ï¼‰ï¼š\n\n"
            "1. **äº‹å®žå±‚éªŒè¯**ï¼šé¦–å…ˆéœ€è¦åŒºåˆ†æ˜¯æ”¿ç­–ææ¡ˆã€å®˜æ–¹å£°æ˜Žè¿˜æ˜¯å·²ç«‹æ³•ç”Ÿæ•ˆã€‚ä¸­å›½åª’ä½“é€šå¸¸æŠ¥é“æ”¿ç­–æ¡†æž¶ä¸Žå®è§‚ç›®æ ‡ï¼Œ"
            "æ¬§ç¾Žåª’ä½“èšç„¦å¸‚åœºååº”ä¸Žèµ„æœ¬æµåŠ¨ï¼ŒåŠå²›è§†è§’å¯èƒ½å…³æ³¨å¯¹å‘å±•ä¸­å›½å®¶è´¸æ˜“çš„å½±å“ã€‚\n\n"
            "2. **é¢„æœŸå±‚è§£æž„**ï¼šæ ‡é¢˜æƒ…ç»ªå¸¸æœ‰æ”¾å¤§æ•ˆåº”ã€‚å»ºè®®åŒæ—¶æŸ¥çœ‹å€ºåˆ¸æ”¶ç›ŠçŽ‡ï¼ˆç¾Žå€º10å¹´æœŸï¼‰ã€ç¾Žå…ƒæŒ‡æ•°ï¼ˆDXYï¼‰ã€"
            "åŽŸæ²¹ä»·æ ¼ï¼ˆBrentï¼‰çš„å³æ—¶å˜åŠ¨ï¼Œè¿™ä¸‰é¡¹æ˜¯åˆ¤æ–­è´¢ç»æ–°é—»çœŸå®žå½±å“çš„é¢†å…ˆæŒ‡æ ‡ã€‚\n\n"
            "3. **æ‰§è¡Œå±‚è·Ÿè¸ª**ï¼šæœ€ç»ˆè¦çœ‹ä¼ä¸šè´¢æŠ¥ä¸­çš„æˆæœ¬å˜åŒ–ã€äº§ä¸šé“¾è°ƒç ”ä¸­çš„è®¢å•æ•°æ®ã€ä»¥åŠå›½é™…èµ„é‡‘æµå‘æŠ¥å‘Šã€‚"
            "å•ä¸€åª’ä½“æŠ¥é“å¾€å¾€ç¼ºå°‘è¿™äº›åŽç»­éªŒè¯çŽ¯èŠ‚ã€‚\n\n"
            "å»ºè®®æ“ä½œï¼šå¯¹è´¢ç»æ–°é—»ä¿æŒ48å°æ—¶è§‚å¯ŸæœŸï¼Œç­‰å¾…å¸‚åœºæ¶ˆåŒ–ä¸Žæ›´å¤šæ•°æ®æŠ«éœ²åŽå†åšåˆ¤æ–­ã€‚"
        )

    # åœ°ç¼˜å†²çªç±»
    elif any(k in combined for k in ["å†²çª", "æˆ˜äº‰", "è¢­å‡»", "åœç«", "å¯¼å¼¹", "å†›äº‹", "è¾¹å¢ƒ", "äººé“", "æ­¦å™¨", "é˜²å¾¡", "å†›é˜Ÿ", "å£«å…µ"]):
        return (
            "âš”ï¸ æˆ‘çš„æ·±åº¦åˆ†æžï¼ˆåœ°ç¼˜å†²çªç±»ï¼‰ï¼š\n\n"
            "1. **å™äº‹æ¡†æž¶å·®å¼‚**ï¼šä¸­å›½æŠ¥é“å¼ºè°ƒå¤šè¾¹å¤–äº¤ä¸Žåœ°åŒºç¨³å®šæ¡†æž¶ï¼Œå¸¸å¼•è¿°å®˜æ–¹ç«‹åœºä¸Žè”åˆå›½å†³è®®ï¼›"
            "æ¬§ç¾ŽæŠ¥é“ä¾§é‡æˆ˜ç•¥åšå¼ˆã€ç›Ÿå‹åè°ƒä¸Žå®‰å…¨å¨èƒè¯„ä¼°ï¼›åŠå²›è§†è§’èšç„¦å¹³æ°‘ä¼¤äº¡ã€äººé“å±æœºä¸ŽçŽ°åœºçºªå®žã€‚\n\n"
            "2. **äº‹å®žäº¤å‰éªŒè¯**ï¼šå»ºè®®åˆ¶ä½œæ—¶é—´çº¿å¯¹æ¯”è¡¨ï¼Œæ ‡æ³¨ä¸‰æ–¹éƒ½ç¡®è®¤çš„æ ¸å¿ƒäº‹å®žï¼ˆæ—¶é—´ã€åœ°ç‚¹ã€ä¼¤äº¡æ•°å­—ã€æ­¦å™¨ç±»åž‹ï¼‰ï¼Œ"
            "å†å•ç‹¬åˆ—å‡ºå„æ–¹ç‹¬æœ‰çš„è¡¥å……ä¿¡æ¯æˆ–è§£è¯»è§’åº¦ã€‚\n\n"
            "3. **å½±å“è¯„ä¼°çŸ©é˜µ**ï¼šçŸ­æœŸçœ‹èˆªè¿æŒ‡æ•°ï¼ˆBDIï¼‰ã€åŽŸæ²¹æœŸè´§ï¼ˆWTI/Brentï¼‰ã€é»„é‡‘ä»·æ ¼ï¼›"
            "ä¸­æœŸçœ‹ç›¸å…³å›½å®¶ä¸»æƒCDSåˆ©å·®ã€è´§å¸æ±‡çŽ‡æ³¢åŠ¨ï¼›é•¿æœŸçœ‹åŒºåŸŸä¾›åº”é“¾é‡æž„å¯èƒ½ã€‚\n\n"
            "è­¦æƒ•ç‚¹ï¼šé¿å…è¿‡æ—©æŽ¥å—å•ä¸€å½’å› å™äº‹ï¼Œå†²çªäº‹ä»¶å¾€å¾€æœ‰å¤æ‚çš„åŽ†å²è„‰ç»œä¸Žä»£ç†æˆ˜äº‰èƒŒæ™¯ã€‚"
        )

    # ç§‘æŠ€å¤ªç©ºç±»
    elif any(k in combined for k in ["NASA", "å¤ªç©º", "å®‡èˆª", "å«æ˜Ÿ", "ç«ç®­", "èˆªå¤©", "æœˆçƒ", "ç«æ˜Ÿ", "æŽ¢ç´¢", "ç§‘æŠ€", "åˆ›æ–°", "äººå·¥æ™ºèƒ½", "AI"]):
        return (
            "ðŸš€ æˆ‘çš„æ·±åº¦åˆ†æžï¼ˆç§‘æŠ€å¤ªç©ºç±»ï¼‰ï¼š\n\n"
            "1. **æŠ¥é“è§’åº¦å¯¹æ¯”**ï¼šä¸­å›½åª’ä½“çªå‡ºå›½å®¶ç§‘æŠ€æˆå°±ä¸Žå·¥ç¨‹çªç ´ï¼Œå¼ºè°ƒè‡ªä¸»åˆ›æ–°ä¸Žå›¢é˜Ÿåä½œï¼›"
            "æ¬§ç¾Žåª’ä½“æ³¨é‡æŠ€æœ¯ç»†èŠ‚ã€å•†ä¸šåº”ç”¨ä¸Žå›½é™…ç«žäº‰ï¼›åŠå²›è§†è§’å¯èƒ½å…³æ³¨ç§‘æŠ€ä¼¦ç†ã€å…¨çƒåˆä½œä¸Žå‘å±•ä¸­å›½å®¶å‚ä¸Žã€‚\n\n"
            "2. **æŠ€æœ¯æˆç†Ÿåº¦è¯„ä¼°**ï¼šåŒºåˆ†æ¦‚å¿µéªŒè¯ã€åŽŸåž‹æµ‹è¯•ã€æ­£å¼éƒ¨ç½²ç­‰é˜¶æ®µã€‚å¤ªç©ºä»»åŠ¡å°¤å…¶è¦å…³æ³¨å‘å°„çª—å£ã€"
            "ä»»åŠ¡æ—¶é•¿ã€æœ‰æ•ˆè½½è·æˆåŠŸçŽ‡ç­‰ç¡¬æŒ‡æ ‡ï¼Œè€Œéžä»…ä»…å®£ä¼ å£å¾„ã€‚\n\n"
            "3. **äº§ä¸šé“¾å½±å“**ï¼šèˆªå¤©ç§‘æŠ€å¸¦åŠ¨æ–°ææ–™ã€é€šä¿¡ã€å¯¼èˆªã€é¥æ„Ÿç­‰å¤šä¸ªäº§ä¸šé“¾ã€‚"
            "å»ºè®®è·Ÿè¸ªç›¸å…³ä¸Šå¸‚å…¬å¸è¡¨çŽ°ã€ä¸“åˆ©å‘å¸ƒé¢‘çŽ‡ã€å›½é™…åˆä½œåè®®ç­¾ç½²æƒ…å†µã€‚\n\n"
            "è§‚å¯Ÿå»ºè®®ï¼šç§‘æŠ€æ–°é—»éœ€ç»“åˆä¸“ä¸šæœŸåˆŠè®ºæ–‡ä¸Žå·¥ç¨‹å¸ˆç¤¾ç¾¤è®¨è®ºï¼Œé¿å…ä»…ä¾èµ–å¤§ä¼—åª’ä½“æŠ¥é“ã€‚"
        )

    # æ”¿æ²»å¤–äº¤ç±»
    elif any(k in combined for k in ["å¤–äº¤", "è®¿é—®", "ä¼šè°ˆ", "åè®®", "æ¡çº¦", "å³°ä¼š", "è”åˆå›½", "åˆ¶è£", "æŠ—è®®", "é€‰ä¸¾", "æ€»ç»Ÿ", "æ€»ç†"]):
        return (
            "ðŸ›ï¸ æˆ‘çš„æ·±åº¦åˆ†æžï¼ˆæ”¿æ²»å¤–äº¤ç±»ï¼‰ï¼š\n\n"
            "1. **è®®ç¨‹è®¾ç½®åˆ†æž**ï¼šä¸­å›½æŠ¥é“å¼ºè°ƒåŒè¾¹å…³ç³»ä¸ŽåŠ¡å®žåˆä½œï¼Œèšç„¦å…·ä½“æˆæžœä¸Žå…±è¯†æ–‡ä»¶ï¼›"
            "æ¬§ç¾Žåª’ä½“å…³æ³¨æƒåŠ›åŠ¨æ€ã€æˆ˜ç•¥æ„å›¾ä¸Žæ½œåœ¨æ‘©æ“¦ç‚¹ï¼›åŠå²›è§†è§’å¸¸ä»Žå…¨çƒå—æ–¹è§†è§’åˆ†æžæƒåŠ›å¹³è¡¡å˜åŒ–ã€‚\n\n"
            "2. **ä¿¡å·è§£è¯»å±‚æ¬¡**ï¼šè¡¨å±‚æ˜¯å®˜æ–¹å£°æ˜Žä¸Žç¤¼ä»ªå®‰æŽ’ï¼Œä¸­å±‚æ˜¯éšè¡Œäººå‘˜çº§åˆ«ä¸Žè®®ç¨‹æ—¶é•¿ï¼Œ"
            "æ·±å±‚æ˜¯åŽç»­æ”¿ç­–è°ƒæ•´ä¸Žèµ„é‡‘æµå‘ã€‚å¤–äº¤æ–°é—»éœ€è¦å¤šå±‚æ¬¡ä¿¡å·äº¤å‰éªŒè¯ã€‚\n\n"
            "3. **åŽ†å²å‚ç…§ç³»**ï¼šå½“å‰äº‹ä»¶åº”æ”¾åœ¨è‡³å°‘10å¹´åŒè¾¹å…³ç³»è„‰ç»œä¸­ç†è§£ï¼Œ"
            "å…³æ³¨æ­¤å‰ç±»ä¼¼æƒ…å¢ƒä¸‹çš„å„æ–¹ååº”æ¨¡å¼ä¸Žæœ€ç»ˆç»“æžœã€‚\n\n"
            "å…³é”®æé†’ï¼šæ”¿æ²»å¤–äº¤æŠ¥é“æœ€æ˜“å—æ„è¯†å½¢æ€æ»¤é•œå½±å“ï¼Œå»ºè®®åŒæ—¶æŸ¥é˜…å„æ–¹æ™ºåº“ç®€æŠ¥ä¸Žå­¦æœ¯åˆ†æžã€‚"
        )

    # ç¤¾ä¼šæ°‘ç”Ÿç±»
    elif any(k in combined for k in ["æ°‘ç”Ÿ", "æ•™è‚²", "åŒ»ç–—", "å¥åº·", "ä½æˆ¿", "å°±ä¸š", "æ”¶å…¥", "æ¶ˆè´¹", "å…»è€", "ç¤¾ä¿", "ç¦åˆ©", "äººå£"]):
        return (
            "ðŸ¥ æˆ‘çš„æ·±åº¦åˆ†æžï¼ˆç¤¾ä¼šæ°‘ç”Ÿç±»ï¼‰ï¼š\n\n"
            "1. **æ”¿ç­–è½åœ°å·®å¼‚**ï¼šä¸­å›½æŠ¥é“ä¾§é‡æ”¿ç­–å‡ºå°ä¸Žè¯•ç‚¹æ•ˆæžœï¼Œå¼ºè°ƒæ”¿åºœæŠ•å…¥ä¸Žè¦†ç›–çŽ‡æå‡ï¼›"
            "æ¬§ç¾Žåª’ä½“å…³æ³¨ä¸ªä½“æ¡ˆä¾‹ã€åˆ¶åº¦æ¯”è¾ƒä¸Žç¤¾ä¼šå…¬å¹³ï¼›åŠå²›è§†è§’å¯èƒ½èšç„¦å…¨çƒä¸å¹³ç­‰ä¸Žèµ„æºåˆ†é…ã€‚\n\n"
            "2. **æ•°æ®æºå¯¹æ¯”**ï¼šæ°‘ç”Ÿè®®é¢˜éœ€è¦å…·ä½“æ•°æ®æ”¯æŒã€‚å»ºè®®å¯¹æ¯”å®˜æ–¹ç»Ÿè®¡æ•°æ®ã€å­¦æœ¯è°ƒç ”æŠ¥å‘Šã€"
            "å›½é™…ç»„ç»‡è¯„ä¼°ä¸Žæ°‘é—´è°ƒæŸ¥ï¼Œæ³¨æ„ç»Ÿè®¡å£å¾„ä¸Žæ ·æœ¬ä»£è¡¨æ€§çš„å·®å¼‚ã€‚\n\n"
            "3. **é•¿æœŸè¶‹åŠ¿è§‚å¯Ÿ**ï¼šç¤¾ä¼šæ”¿ç­–æ•ˆæžœå¾€å¾€æœ‰3-5å¹´æ»žåŽæœŸã€‚å…³æ³¨ç›¸å…³é¢†åŸŸçš„å­¦æœ¯è®ºæ–‡å‘è¡¨ã€"
            "NGOè¯„ä¼°æŠ¥å‘Šã€ä»¥åŠå—å½±å“ç¾¤ä½“çš„é•¿æœŸè¿½è¸ªç ”ç©¶ã€‚\n\n"
            "åˆ†æžå»ºè®®ï¼šé¿å…ä»…å‡­çŸ­æœŸåª’ä½“æŠ¥é“åˆ¤æ–­é•¿æœŸç¤¾ä¼šè¶‹åŠ¿ï¼Œæ°‘ç”Ÿè®®é¢˜éœ€è¦è€å¿ƒä¸Žå¤šç»´æ•°æ®ã€‚"
        )

    # é»˜è®¤ç»¼åˆç±»
    else:
        return (
            "ðŸ” æˆ‘çš„æ·±åº¦åˆ†æžï¼ˆç»¼åˆç±»ï¼‰ï¼š\n\n"
            "1. **ä¿¡æ¯çŸ©é˜µæž„å»º**ï¼šå»ºè®®åˆ›å»ºä¸‰æ–¹æŠ¥é“å¯¹æ¯”è¡¨æ ¼ï¼Œåˆ—å‡ºäº‹ä»¶æ ¸å¿ƒè¦ç´ ï¼ˆæ—¶é—´ã€åœ°ç‚¹ã€ä¸»ä½“ã€è¡ŒåŠ¨ã€ç»“æžœï¼‰ï¼Œ"
            "å†æ ‡æ³¨å„æ–¹ç‹¬æœ‰çš„èƒŒæ™¯è¡¥å……ã€å› æžœè§£é‡Šä¸Žä»·å€¼åˆ¤æ–­ã€‚\n\n"
            "2. **ä¿¡æºå¯é æ€§è¯„ä¼°**ï¼šæŸ¥éªŒå„æ–¹å¼•ç”¨çš„åŽŸå§‹ä¿¡æºï¼ˆå®˜æ–¹æ–‡ä»¶ã€çŽ°åœºå½±åƒã€ä¸“å®¶è®¿è°ˆã€æ•°æ®æŠ¥å‘Šï¼‰ï¼Œ"
            "æ³¨æ„åŒ¿åä¿¡æºä¸Žæ˜Žç¡®ç½²åçš„å·®å¼‚ï¼Œä»¥åŠä¿¡æºçš„æ—¶é—´æˆ³ä¸Žåœ°ç†ä½ç½®ã€‚\n\n"
            "3. **è®¤çŸ¥åå·®è¯†åˆ«**ï¼šè­¦æƒ•ç¡®è®¤åè¯¯ï¼ˆåªå…³æ³¨æ”¯æŒè‡ªå·±è§‚ç‚¹çš„æŠ¥é“ï¼‰ã€å¯å¾—æ€§åè¯¯ï¼ˆè¿‡åº¦ä¾èµ–æœ€æ˜“èŽ·å–çš„ä¿¡æ¯ï¼‰ã€"
            "æ¡†æž¶æ•ˆåº”ï¼ˆåŒä¸€äº‹å®žä¸åŒè¡¨è¿°å¯¼è‡´ä¸åŒåˆ¤æ–­ï¼‰ã€‚\n\n"
            "æœ€ç»ˆå»ºè®®ï¼šé‡è¦äº‹ä»¶åº”ç­‰å¾…24-48å°æ—¶ï¼Œå¾…æ›´å¤šä¿¡æ¯æµ®çŽ°ä¸Žäº‹å®žæ ¸æŸ¥å®ŒæˆåŽå†å½¢æˆç¨³å®šåˆ¤æ–­ã€‚"
        )


def summary_view(event):
    c = event.get("ä¸­å›½")
    u = event.get("ç¾Žå›½")
    i = event.get("ä¼Šæ–¯å…°")
    
    # æå–å…³é”®ä¿¡æ¯ç”¨äºŽä¸ªæ€§åŒ–æ€»ç»“
    event_title = event.get("event_hint_zh", "") or event.get("event_hint", "")
    categories = []
    if any(k in event_title for k in ["å…³ç¨Ž", "è´¸æ˜“", "ç»æµŽ", "è‚¡å¸‚"]):
        categories.append("è´¢ç»ç»æµŽ")
    if any(k in event_title for k in ["å†²çª", "æˆ˜äº‰", "å†›äº‹"]):
        categories.append("åœ°ç¼˜å®‰å…¨")
    if any(k in event_title for k in ["NASA", "å¤ªç©º", "ç§‘æŠ€"]):
        categories.append("ç§‘æŠ€åˆ›æ–°")
    if any(k in event_title for k in ["å¤–äº¤", "åè®®", "å³°ä¼š"]):
        categories.append("æ”¿æ²»å¤–äº¤")
    if any(k in event_title for k in ["æ°‘ç”Ÿ", "æ•™è‚²", "åŒ»ç–—"]):
        categories.append("ç¤¾ä¼šæ°‘ç”Ÿ")
    
    category_str = "ã€".join(categories) if categories else "ç»¼åˆ"
    
    parts = []
    parts.append(f"ðŸ”¬ ä¸‰æ–¹è§†è§’æ·±åº¦æ€»ç»“ï¼ˆ{category_str}ç±»äº‹ä»¶ï¼‰\n\n")
    
    if c:
        parts.append("ðŸ‡¨ðŸ‡³ **ä¸­å›½è§†è§’ç‰¹å¾**ï¼šé€šå¸¸èšç„¦æ”¿ç­–æ¡†æž¶ã€é•¿æœŸè§„åˆ’ã€ç¤¾ä¼šç¨³å®šä¸Žé›†ä½“æˆå°±ï¼›æŠ¥é“é£Žæ ¼ç¨³é‡ï¼Œ"
                    "å¼ºè°ƒåˆ¶åº¦ä¼˜åŠ¿ä¸Žæ²»ç†æ•ˆèƒ½ï¼›åœ¨æŠ€æœ¯ç±»æ–°é—»ä¸­çªå‡ºè‡ªä¸»åˆ›æ–°ï¼Œåœ¨å¤–äº¤æ–°é—»ä¸­å¼ºè°ƒåˆä½œå…±èµ¢ã€‚\n\n")
    
    if u:
        parts.append("ðŸ‡ºðŸ‡¸ **æ¬§ç¾Žè§†è§’ç‰¹å¾**ï¼šä¾§é‡ä¸ªä½“æƒåˆ©ã€åˆ¶åº¦åˆ¶è¡¡ã€å¸‚åœºç«žäº‰ä¸Žæˆ˜ç•¥åšå¼ˆï¼›æŠ¥é“å¸¸é‡‡ç”¨æ‰¹åˆ¤æ€§è´¨ç–‘è§’åº¦ï¼Œ"
                    "å…³æ³¨æƒåŠ›åŠ¨æ€ä¸Žæ½œåœ¨é£Žé™©ï¼›åœ¨è´¢ç»æ–°é—»ä¸­å¼ºè°ƒå¸‚åœºååº”ï¼Œåœ¨åœ°ç¼˜æ–°é—»ä¸­åˆ†æžå®‰å…¨å½±å“ã€‚\n\n")
    
    if i:
        parts.append("ðŸŒ **ä¼Šæ–¯å…°/åŠå²›è§†è§’ç‰¹å¾**ï¼šå¾€å¾€ä»Žå…¨çƒå—æ–¹ä¸Žå‘å±•ä¸­å›½å®¶ç«‹åœºå‡ºå‘ï¼Œå…³æ³¨çŽ°åœºç»†èŠ‚ã€"
                    "äººé“åŽæžœä¸ŽæƒåŠ›ä¸å¹³ç­‰ï¼›æŠ¥é“é£Žæ ¼æ›´å…·å™äº‹æ€§ï¼Œå¼ºè°ƒæ™®é€šäººçš„ç»åŽ†ä¸Žæƒ…æ„Ÿï¼›"
                    "å¸¸ä¸ºè¥¿æ–¹ä¸»æµå™äº‹æä¾›é‡è¦çš„è¡¥å……ä¸Žåˆ¶è¡¡è§†è§’ã€‚\n\n")
    
    parts.append("ðŸ“ˆ **æ•´åˆåˆ†æžå»ºè®®**ï¼š\n")
    parts.append("1. ç”¨ä¸­å›½è§†è§’ç†è§£æ”¿ç­–æ„å›¾ä¸Žé•¿æœŸæ¡†æž¶\n")
    parts.append("2. ç”¨æ¬§ç¾Žè§†è§’è¯„ä¼°å¸‚åœºååº”ä¸Žé£Žé™©å˜é‡\n")
    parts.append("3. ç”¨åŠå²›è§†è§’æ„Ÿå—çŽ°åœºçŽ°å®žä¸Žäººæ–‡ç»´åº¦\n\n")
    
    parts.append("ðŸ’¡ **æœ€ç»ˆæ´žå¯Ÿ**ï¼šçœŸæ­£çš„ä¿¡æ¯ä¼˜åŠ¿ä¸åœ¨äºŽèŽ·å–æ›´å¤šåŒç±»æŠ¥é“ï¼Œè€Œåœ¨äºŽåŒæ—¶æŽŒæ¡ä¸åŒè®¤çŸ¥æ¡†æž¶ï¼Œ"
                "ä»Žè€Œåœ¨å¤æ‚ä¸–ç•Œä¸­å½¢æˆæ›´ç«‹ä½“ã€æ›´æŠ—åå·®çš„åˆ¤æ–­èƒ½åŠ›ã€‚")
    
    return "".join(parts)


def build_triangle(sources):
    cn = sources.get("ä¸­å›½", [])
    us = sources.get("ç¾Žå›½ï¼ˆæ¬§ç¾Žåª’ä½“ï¼‰", [])
    aj = sources.get("ä¼Šæ–¯å…°ï¼ˆåŠå²›ç­‰ï¼‰", [])

    events = []
    seeds = [("ä¸­å›½", x) for x in cn] + [("ç¾Žå›½", x) for x in us] + [("ä¼Šæ–¯å…°", x) for x in aj]

    for src, seed in seeds:
        c = seed if src == "ä¸­å›½" else None
        u = seed if src == "ç¾Žå›½" else None
        a = seed if src == "ä¼Šæ–¯å…°" else None

        sc = 1 if c else 0
        su = 1 if u else 0
        sa = 1 if a else 0

        if c is None:
            c, sc = best_for(seed, cn)
        if u is None:
            u, su = best_for(seed, us)
        if a is None:
            a, sa = best_for(seed, aj)

        media_count = (1 if (c and sc > 0) else 0) + (1 if (u and su > 0) else 0) + (1 if (a and sa > 0) else 0)
        if media_count < 2:
            continue

        e = {
            "event_hint": seed["title"],
            "event_hint_zh": seed.get("title_zh", seed["title"]),
            "event_hint_en": seed.get("title_en", seed["title"]),
            "ä¸­å›½": c if (c and sc > 0) else None,
            "ç¾Žå›½": u if (u and su > 0) else None,
            "ä¼Šæ–¯å…°": a if (a and sa > 0) else None,
            "media_count": media_count,
            "score": sc + su + sa,
        }
        e["my_view"] = ai_view(e)
        e["summary"] = summary_view(e)
        events.append(e)

    uniq, seen = [], set()
    for e in sorted(events, key=lambda x: (x["media_count"], x["score"]), reverse=True):
        k = e.get("event_hint_zh", "")[:90]
        if k in seen:
            continue
        seen.add(k)
        uniq.append(e)

    return uniq[:MAX_TRIANGLE]


def main():
    payload = {
        "generated_at": datetime.now(TZ).strftime("%Y-%m-%d %H:%M:%S %Z"),
        "sources": {},
        "triangle": [],
        "errors": {},
    }

    for name, urls in SOURCES.items():
        merged, errs = [], []
        for url in urls:
            try:
                merged.extend(fetch_rss(url))
            except Exception as e:
                errs.append(f"{url}: {e}")

        seen, uniq = set(), []
        for it in merged:
            key = (it.get("title", ""), it.get("link", ""))
            if key in seen:
                continue
            seen.add(key)
            uniq.append(it)

        payload["sources"][name] = uniq[:MAX_CARD_ITEMS]
        if errs and not uniq:
            payload["errors"][name] = " | ".join(errs)

    payload["triangle"] = build_triangle(payload["sources"])

    OUT.parent.mkdir(parents=True, exist_ok=True)
    OUT.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8")
    print(f"âœ… Updated: {OUT}")


if __name__ == "__main__":
    main()
